{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSZFxen9A_wF"
      },
      "source": [
        "# DCGAN Workspace 3 - Precision Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xej_QDNEA_wG"
      },
      "source": [
        "Notes\n",
        "\n",
        "When first implemented mixed precision, for the first 10 epochs the discriminator loss got very close to 0 while the generator loss kept growing (towards 10) but then suddenly in the 10th epoch they came back to more normal values ~700. This had first led me to believe the model would not work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lbtD1SewA_wH",
        "outputId": "16a40d79-1b25-4f79-d0ab-2bf50bfa9258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "dcgan_base - INFO - Program started\n",
            "INFO:dcgan_base:Program started\n",
            "dcgan_base - INFO - ------------------------------------------------------------\n",
            "INFO:dcgan_base:------------------------------------------------------------\n",
            "dcgan_base - INFO - Discriminator created\n",
            "INFO:dcgan_base:Discriminator created\n",
            "dcgan_base - INFO - Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 14, 14, 64)        640       \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3136)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 3137      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40705 (159.00 KB)\n",
            "Trainable params: 40705 (159.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            "INFO:dcgan_base:Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 14, 14, 64)        640       \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3136)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 3137      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40705 (159.00 KB)\n",
            "Trainable params: 40705 (159.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            "dcgan_base - INFO - ------------------------------------------------------------\n",
            "INFO:dcgan_base:------------------------------------------------------------\n",
            "dcgan_base - INFO - Generator created\n",
            "INFO:dcgan_base:Generator created\n",
            "dcgan_base - INFO - Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 6272)              633472    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 6272)              0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTr  (None, 14, 14, 128)       262272    \n",
            " anspose)                                                        \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2D  (None, 28, 28, 128)       262272    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 28, 28, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 1)         6273      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1164289 (4.44 MB)\n",
            "Trainable params: 1164289 (4.44 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            "INFO:dcgan_base:Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 6272)              633472    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 6272)              0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTr  (None, 14, 14, 128)       262272    \n",
            " anspose)                                                        \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2D  (None, 28, 28, 128)       262272    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 28, 28, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 1)         6273      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1164289 (4.44 MB)\n",
            "Trainable params: 1164289 (4.44 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            "dcgan_base - INFO - ------------------------------------------------------------\n",
            "INFO:dcgan_base:------------------------------------------------------------\n",
            "dcgan_base - INFO - GAN created\n",
            "INFO:dcgan_base:GAN created\n",
            "dcgan_base - INFO - Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_1 (Sequential)   (None, 28, 28, 1)         1164289   \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 1)                 40705     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1204994 (4.60 MB)\n",
            "Trainable params: 1164289 (4.44 MB)\n",
            "Non-trainable params: 40705 (159.00 KB)\n",
            "_________________________________________________________________\n",
            "\n",
            "INFO:dcgan_base:Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_1 (Sequential)   (None, 28, 28, 1)         1164289   \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 1)                 40705     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1204994 (4.60 MB)\n",
            "Trainable params: 1164289 (4.44 MB)\n",
            "Non-trainable params: 40705 (159.00 KB)\n",
            "_________________________________________________________________\n",
            "\n",
            "dcgan_base - INFO - ------------------------------------------------------------\n",
            "INFO:dcgan_base:------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "dcgan_base - INFO - Training started\n",
            "INFO:dcgan_base:Training started\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 3s 4ms/step\n",
            ">1, 1/468, d=0.711, g=0.721\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 2/468, d=0.692, g=0.734\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 3/468, d=0.686, g=0.754\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 4/468, d=0.681, g=0.777\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 5/468, d=0.682, g=0.786\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 6/468, d=0.671, g=0.797\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 7/468, d=0.662, g=0.811\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 8/468, d=0.653, g=0.830\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 9/468, d=0.653, g=0.831\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 10/468, d=0.652, g=0.838\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 11/468, d=0.653, g=0.826\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 12/468, d=0.653, g=0.817\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 13/468, d=0.658, g=0.791\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 14/468, d=0.661, g=0.769\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 15/468, d=0.665, g=0.748\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 16/468, d=0.668, g=0.732\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 17/468, d=0.662, g=0.722\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 18/468, d=0.659, g=0.713\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 19/468, d=0.657, g=0.708\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 20/468, d=0.649, g=0.705\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 21/468, d=0.647, g=0.702\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 22/468, d=0.641, g=0.701\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 23/468, d=0.634, g=0.700\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 24/468, d=0.625, g=0.699\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 25/468, d=0.621, g=0.698\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 26/468, d=0.615, g=0.698\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 27/468, d=0.604, g=0.697\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 28/468, d=0.586, g=0.698\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 29/468, d=0.587, g=0.698\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 30/468, d=0.573, g=0.699\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 31/468, d=0.570, g=0.699\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 32/468, d=0.552, g=0.700\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 33/468, d=0.544, g=0.702\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 34/468, d=0.544, g=0.702\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 35/468, d=0.529, g=0.704\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 36/468, d=0.506, g=0.705\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 37/468, d=0.503, g=0.706\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 38/468, d=0.487, g=0.708\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 39/468, d=0.489, g=0.710\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 40/468, d=0.478, g=0.713\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 41/468, d=0.453, g=0.716\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 42/468, d=0.464, g=0.719\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 43/468, d=0.442, g=0.722\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 44/468, d=0.443, g=0.726\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 45/468, d=0.424, g=0.729\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 46/468, d=0.415, g=0.734\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 47/468, d=0.409, g=0.739\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 48/468, d=0.410, g=0.745\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 49/468, d=0.393, g=0.750\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 50/468, d=0.388, g=0.758\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 51/468, d=0.374, g=0.767\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 52/468, d=0.380, g=0.774\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 53/468, d=0.368, g=0.786\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 54/468, d=0.353, g=0.795\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 55/468, d=0.353, g=0.808\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 56/468, d=0.351, g=0.820\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 57/468, d=0.334, g=0.836\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 58/468, d=0.326, g=0.851\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 59/468, d=0.325, g=0.870\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 60/468, d=0.306, g=0.891\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 61/468, d=0.308, g=0.908\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 62/468, d=0.287, g=0.934\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 63/468, d=0.281, g=0.961\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            ">1, 64/468, d=0.273, g=0.988\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 65/468, d=0.265, g=1.020\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 66/468, d=0.256, g=1.052\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 67/468, d=0.245, g=1.084\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 68/468, d=0.245, g=1.120\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 69/468, d=0.233, g=1.159\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 70/468, d=0.211, g=1.201\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 71/468, d=0.209, g=1.246\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 72/468, d=0.194, g=1.293\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 73/468, d=0.188, g=1.339\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 74/468, d=0.180, g=1.390\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 75/468, d=0.171, g=1.438\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 76/468, d=0.163, g=1.496\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 77/468, d=0.154, g=1.543\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 78/468, d=0.143, g=1.592\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 79/468, d=0.143, g=1.652\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 80/468, d=0.129, g=1.707\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 81/468, d=0.130, g=1.760\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 82/468, d=0.120, g=1.818\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 83/468, d=0.119, g=1.873\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            ">1, 84/468, d=0.105, g=1.928\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            ">1, 85/468, d=0.103, g=1.988\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 86/468, d=0.099, g=2.051\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 87/468, d=0.092, g=2.098\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            ">1, 88/468, d=0.080, g=2.150\n",
            "2/2 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-31cf04708d55>\u001b[0m in \u001b[0;36m<cell line: 377>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training started'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training finished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-31cf04708d55>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;31m# train discriminator separately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;31m# train generator - use 1 value to find how often it is wrong to update model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2781\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2782\u001b[0m         ):\n\u001b[0;32m-> 2783\u001b[0;31m             iterator = data_adapter.single_batch_iterator(\n\u001b[0m\u001b[1;32m   2784\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2785\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36msingle_batch_iterator\u001b[0;34m(strategy, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1940\u001b[0m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1941\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1943\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_make_class_weight_map_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensors\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_tensors_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrom_tensors_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m     \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_tensors_op.py\u001b[0m in \u001b[0;36m_from_tensors\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_from_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-private-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_TensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_tensors_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0moutput_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_flat_tensor_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         metadata=self._metadata.SerializeToString())\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, variant_tensor)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \"\"\"\n\u001b[1;32m    236\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;31m# Initialize the options for this dataset and its inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5010\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"get_default_graph\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5011\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5012\u001b[0m   \"\"\"Returns the default graph for the current thread.\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from numpy import expand_dims, ones, zeros, vstack\n",
        "from numpy.random import rand, randint, randn\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, Dropout, LeakyReLU, Conv2DTranspose, Reshape\n",
        "from matplotlib import pyplot\n",
        "import logging\n",
        "import io\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "def initialize_logger():\n",
        "    \"\"\"\n",
        "    Creates a logger for hyperparameters and training data.\n",
        "    \"\"\"\n",
        "    # Get the name of the current script\n",
        "    script_name = 'dcgan_base'\n",
        "    log_filename = f'{script_name}.log'\n",
        "\n",
        "    # Create a custom logger\n",
        "    logger = logging.getLogger(script_name)\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "\n",
        "    # Create handlers\n",
        "    c_handler = logging.StreamHandler()\n",
        "    f_handler = logging.FileHandler(log_filename)\n",
        "    c_handler.setLevel(logging.INFO)\n",
        "    f_handler.setLevel(logging.DEBUG)\n",
        "\n",
        "    # Create formatters and add it to handlers\n",
        "    c_format = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n",
        "    f_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "    c_handler.setFormatter(c_format)\n",
        "    f_handler.setFormatter(f_format)\n",
        "\n",
        "    # Add handlers to the logger\n",
        "    logger.addHandler(c_handler)\n",
        "    logger.addHandler(f_handler)\n",
        "\n",
        "    return logger\n",
        "\n",
        "\n",
        "def log_model_summary(model, logger):\n",
        "    with io.StringIO() as buf, redirect_stdout(buf):\n",
        "        model.summary()\n",
        "        summary = buf.getvalue()\n",
        "    logger.info(summary)\n",
        "\n",
        "\n",
        "def create_discriminator(in_shape=(28,28,1)):\n",
        "    \"\"\"\n",
        "    Creates a discrimator model\n",
        "\n",
        "    Input:\n",
        "    in-shape: This is the shape of the photos that will be put into the discriminator model.\n",
        "\n",
        "    Output:\n",
        "    The model for discriminating fake vs real images\n",
        "    \"\"\"\n",
        "    model =  Sequential()\n",
        "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # compile\n",
        "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_mnist():\n",
        "    \"\"\"\n",
        "    This function loads the MNIST dataset, and scales it to be in a sigmoid (0, 1) range\n",
        "    \"\"\"\n",
        "    (trainX, _), (_, _) = load_data()\n",
        "    # add third dimension for color value\n",
        "    X = expand_dims(trainX, axis=-1)\n",
        "    X = X.astype('float32')\n",
        "    X = X / 255.0\n",
        "    return X\n",
        "\n",
        "\n",
        "\n",
        "def select_real_samples(dataset, n_samples):\n",
        "    \"\"\"\n",
        "    Selects some number of real samples to train with from the input dataset.\n",
        "    Uses random to select random images. Labels the images as 'real' with label = 1\n",
        "\n",
        "    Inputs:\n",
        "    dataset: Input dataset(MNIST)\n",
        "    n_sample: number of samples to select\n",
        "\n",
        "    Return:\n",
        "    X: Selected images\n",
        "    y: tags for images\n",
        "    \"\"\"\n",
        "    # get n number of random images from dataset\n",
        "    i = randint(0, dataset.shape[0], n_samples)\n",
        "\n",
        "    X = dataset[i]\n",
        "    y = ones((n_samples, 1))\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "\n",
        "def initial_create_fake_samples(n_samples):\n",
        "    \"\"\"\n",
        "    Creates fake samples to train discriminator with correct dimensions\n",
        "\n",
        "    Input:\n",
        "    n_samples: number of samples to create\n",
        "\n",
        "    Return:\n",
        "    X: fake images\n",
        "    y: image tags for training, 0 to mean not real images\n",
        "    \"\"\"\n",
        "    X = rand(28 * 28 * n_samples)\n",
        "\n",
        "    # Reshape and add tags to show fake\n",
        "    X = X.reshape((n_samples, 28, 28, 1))\n",
        "    y = zeros((n_samples, 1))\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def train_discriminator(model, dataset, iterations=100, batch_size=256):\n",
        "    \"\"\"\n",
        "    Trains the discriminator using mnist dataset and fake images.\n",
        "    Takes half batch size of real and fake for each iteration.\n",
        "\n",
        "    Inputs:\n",
        "    model: input model\n",
        "    dataset: loaded dataset (MNIST)\n",
        "    iterations: number of iterations of training\n",
        "    batch_size: images to train with in each iteration\n",
        "    \"\"\"\n",
        "\n",
        "    for i in range(iterations):\n",
        "        # Select real images and train discriminator\n",
        "        X_real, y_real = select_real_samples(dataset, int(batch_size / 2))\n",
        "        _, real_acc = model.train_on_batch(X_real, y_real)\n",
        "\n",
        "        # Select fake images and train discriminator\n",
        "        X_fake, y_fake = initial_create_fake_samples(int(batch_size / 2))\n",
        "        _, fake_acc = model.train_on_batch(X_fake, y_fake)\n",
        "\n",
        "        #Performance\n",
        "        print(f'>{i+1} real={real_acc*100:.0f}% fake={fake_acc*100:.0f}%')\n",
        "\n",
        "\n",
        "def create_generator(latent_dim):\n",
        "    \"\"\"\n",
        "    Creates a generator model.\n",
        "    Starts with a 7x7 and reshapes to be 14x14 then 28x28.\n",
        "\n",
        "    Input:\n",
        "    latent-dim: Dimension of the latent space\n",
        "\n",
        "    Return:\n",
        "    The generator model\n",
        "    \"\"\"\n",
        "\n",
        "    model = Sequential()\n",
        "    n_nodes = 128 * 7 * 7\n",
        "\n",
        "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Reshape((7, 7, 128)))\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2D(1, (7,7), activation='sigmoid', padding='same'))\n",
        "    return model\n",
        "\n",
        "\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    \"\"\"\n",
        "    Generates points in latent space.\n",
        "    Used as input for the generator\n",
        "\n",
        "    Inputs:\n",
        "    latent_dim: Dimension of the latent space\n",
        "    n_samples: number of samples to generate\n",
        "\n",
        "    Return:\n",
        "    x_input: points in latent space\n",
        "    \"\"\"\n",
        "    x_input = randn(latent_dim * n_samples)\n",
        "    x_input = x_input.reshape(n_samples, latent_dim)\n",
        "    return x_input\n",
        "\n",
        "\n",
        "def create_fake_samples(g_model, latent_dim, n_samples):\n",
        "    \"\"\"\n",
        "    Generates fake samples from the generator model.\n",
        "    Creates labels of 0 for the fake images\n",
        "\n",
        "    Inputs:\n",
        "    g_model: generator model\n",
        "    latent_dim: Dimension of the latent space\n",
        "    n_samples: number of samples to generate\n",
        "\n",
        "    Return:\n",
        "    X: fake images\n",
        "    y: image tags for training, 0 to mean not real\n",
        "    \"\"\"\n",
        "    x_input = generate_latent_points(latent_dim, n_samples)\n",
        "    X = g_model.predict(x_input)\n",
        "    y = zeros((n_samples, 1))\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def create_gan(g_model, d_model):\n",
        "    \"\"\"\n",
        "    Creating the GAN model. The generator is trained but the discriminator is untrainable.\n",
        "\n",
        "    Inputs:\n",
        "    g_model: generator model\n",
        "    d_model: discriminator model\n",
        "\n",
        "    Return:\n",
        "    The GAN model\n",
        "    \"\"\"\n",
        "    d_model.trainable = False\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(g_model)\n",
        "    model.add(d_model)\n",
        "\n",
        "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    return model\n",
        "\n",
        "\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=256):\n",
        "    \"\"\"\n",
        "    Trains the generator and discriminator.\n",
        "\n",
        "    Inputs:\n",
        "    g_model: generator model\n",
        "    d_model: discriminator model\n",
        "    gan_model: GAN model\n",
        "    dataset: MNIST dataset\n",
        "    latent_dim: Dimension of the latent space\n",
        "    n_epochs: number of epochs to train\n",
        "    n_batch: number of images to train with in each iteration\n",
        "    \"\"\"\n",
        "    num_batch = int(dataset.shape[0] / n_batch)\n",
        "    half_batch = int(n_batch / 2)\n",
        "\n",
        "    for i in range(n_epochs):\n",
        "\n",
        "        for j in range(num_batch):\n",
        "            # generate real and fake samples\n",
        "            X_real, y_real = select_real_samples(dataset, half_batch)\n",
        "            X_fake, y_fake = create_fake_samples(g_model, latent_dim, half_batch)\n",
        "\n",
        "            # train discriminator separately\n",
        "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
        "            d_loss, _ = d_model.train_on_batch(X, y)\n",
        "\n",
        "            # train generator - use 1 value to find how often it is wrong to update model\n",
        "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "            y_gan = ones((n_batch, 1))\n",
        "\n",
        "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\n",
        "            print(f'>{i+1}, {j+1}/{num_batch}, d={d_loss:.3f}, g={g_loss:.3f}')\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            performance_summary(i, g_model, d_model, dataset, latent_dim)\n",
        "\n",
        "\n",
        "def create_plot(examples, epoch, n=10):\n",
        "    \"\"\"\n",
        "    Creates a physical picture to look at to see how the training is coming after each 10 epochs\n",
        "\n",
        "    Inputs:\n",
        "    examples: images to plot\n",
        "    epoch: epoch number\n",
        "    n: number of images to plot\n",
        "    \"\"\"\n",
        "    for i in range(n * n):\n",
        "        pyplot.subplot(n, n, 1 + i)\n",
        "        pyplot.axis('off')\n",
        "        pyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
        "    filename = 'generated_plot_e%03d.png' % (epoch+1)\n",
        "    pyplot.savefig(filename)\n",
        "    pyplot.close()\n",
        "\n",
        "\n",
        "def performance_summary(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
        "    \"\"\"\n",
        "    Every 10 epochs, save a copy of the model as well as a plot of generated images.\n",
        "\n",
        "    Inputs:\n",
        "    epoch: epoch number\n",
        "    g_model: generator model\n",
        "    d_model: discriminator model\n",
        "    dataset: MNIST dataset\n",
        "    latent_dim: Dimension of the latent space\n",
        "    n_samples: number of samples to generate\n",
        "    \"\"\"\n",
        "    # take real samples and evaluate discriminator\n",
        "    X_real, y_real = select_real_samples(dataset, n_samples)\n",
        "    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "\n",
        "    # take generated samples and evaluate using discriminator\n",
        "    x_fake, y_fake = create_fake_samples(g_model, latent_dim, n_samples)\n",
        "    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "\n",
        "    # summarize discriminator performance\n",
        "    print(f'>Accuracy real: {acc_real*100:.0f}%, fake: {acc_fake*100:.0f}%')\n",
        "    logger.info(f'>Accuracy real: {acc_real*100:.0f}%, fake: {acc_fake*100:.0f}%')\n",
        "\n",
        "    # create the 10 x 10 plot picture\n",
        "    create_plot(x_fake, epoch)\n",
        "\n",
        "    # save the generator model tile file\n",
        "    filename = 'generator_model_%03d.h5' % (epoch + 1)\n",
        "    g_model.save(filename)\n",
        "\n",
        "\n",
        "# load and prepare mnist training images\n",
        "def load_real_samples():\n",
        "    \"\"\"\n",
        "    Loads the MNIST dataset and scales it to be in a sigmoid (0, 1) range\n",
        "    \"\"\"\n",
        "    (trainX, _), (_, _) = load_data()\n",
        "    X = expand_dims(trainX, axis=-1)\n",
        "    X = X.astype('float32')\n",
        "    X = X / 255.0\n",
        "    return X\n",
        "\n",
        "\n",
        "\n",
        "logger = initialize_logger()\n",
        "logger.info('Program started')\n",
        "logger.info('------------------------------------------------------------')\n",
        "\n",
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# create the discriminator\n",
        "d_model = create_discriminator()\n",
        "logger.info('Discriminator created')\n",
        "log_model_summary(d_model, logger)\n",
        "logger.info('------------------------------------------------------------')\n",
        "# create the generator\n",
        "g_model = create_generator(latent_dim)\n",
        "logger.info('Generator created')\n",
        "log_model_summary(g_model, logger)\n",
        "logger.info('------------------------------------------------------------')\n",
        "# create the gan\n",
        "gan_model = create_gan(g_model, d_model)\n",
        "logger.info('GAN created')\n",
        "log_model_summary(gan_model, logger)\n",
        "logger.info('------------------------------------------------------------')\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "# train model\n",
        "logger.info('Training started')\n",
        "train(g_model, d_model, gan_model, dataset, latent_dim)\n",
        "\n",
        "logger.info('Training finished')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}